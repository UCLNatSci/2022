{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1309525e",
   "metadata": {},
   "source": [
    "# Curve fitting\n",
    "\n",
    "Exponential function, logistic function, Monod function\n",
    "Limiting behaviour of these, links with growth and decay\n",
    "It will cover the informal notion of a limit\n",
    "\n",
    "by minimising the squares of the residual errors\n",
    "\n",
    "\n",
    "## Global temperature anomaly\n",
    "\n",
    "Loosely speaking, radiative forcing refers to the amount of additional solar energy (Watts per square metre, Wm-2) absorbed by the Earth due to climate factors.\n",
    "\n",
    "An estimate of radiative forcing due to atmospheric $\\ce{CO2}$ concentrations was given by the Swedish scientist [Svante Arrhenius](https://en.wikipedia.org/wiki/Svante_Arrhenius), who received the Nobel prize for Chemistry in 1903. The relationship can be written in the following form\n",
    "\n",
    "```{math}\n",
    ":label: arrhenius\n",
    "\\Delta F=\\alpha \\ln(C/C_0),\n",
    "```\n",
    "\n",
    "where $\\alpha$ is a constant,\n",
    "* $C$ is the atmospheric concentration of $\\ce{CO2}$ at time $t$\n",
    "* $C_0$ is the atmospheric concentration of $\\ce{CO2}$ at reference time\n",
    "* $\\Delta F$ is the amount of additional solar energy due to radiative forcing\n",
    "\n",
    "```{exercise}\n",
    "Estimates have placed the value of $\\alpha$ in {eq}`arrhenius` at around 5.35Wm-2 for Earth's atmosphere. Calculate the amount of additional solar energy due to radiative forcing between pre-industrial levels (CO2 approx 275ppm) to present day (CO2 approx 410ppm).\n",
    "```\n",
    "\n",
    "```{toggle}\n",
    "\\begin{equation*}\n",
    "\\Delta F = 5.35\\times \\ln\\left(\\frac{410}{275}\\right) \\simeq 2.14 \\text{Wm-2}\n",
    "\\end{equation*}\n",
    "```\n",
    "\n",
    "Multiplying $\\Delta F$ by the Earth's total area gets the total warming energy in Watts. This results in a figure that is approximately 60 times larger than the global annual energy consumption (~18TW). But what impact does it have on temperature?\n",
    "\n",
    " We will assume that the change in temperature $\\Delta T$ is linearly proportional to the increase in energy, which we may write as:\n",
    "\n",
    "```{math}\n",
    ":label: arrhenius-2\n",
    "\\Delta T = \\lambda \\Delta F = \\hat{\\alpha}\\ln(C/C_0)\n",
    "```\n",
    "\n",
    "The value of the constant $\\hat{\\alpha}$ may be estimated from data.\n",
    "\n",
    "```{exercise}\n",
    "The dataset [`climate-change-2.csv`](https://liveuclac-my.sharepoint.com/:x:/r/personal/ucqssjm_ucl_ac_uk/Documents/Shared%20with%20Everyone/nsci0006_data/climate-change-2.csv?d=wa78acfaf46614d0db87f10b435bc5752&csf=1&web=1&e=YOVb1H) shows $\\ce{CO2}$ levels ($C$) alongside the global temperature anomaly $\\Delta T$. Produce a plot of $\\Delta T$ against $\\ln(C/C_0)$, taking $C_0$ to be the first value in the dataset.\n",
    "\n",
    "Data for this question were obtained from [ourworldindata.org](https://ourworldindata.org/co2-and-other-greenhouse-gas-emissions).\n",
    "```\n",
    "\n",
    "````{toggle}\n",
    "Code to import and plot the datapoints is given below\n",
    "```{code}\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#import the data\n",
    "df = pd.read_csv('climate-change-2.csv')\n",
    "C=df['CO2 (ppm)']\n",
    "y=df['Temp anom (K)']\n",
    "\n",
    "x=np.log(C/C[0])     #x=log(C/C0)\n",
    "plt.plot(x,y,'o')    #plot\n",
    "\n",
    "#prettify\n",
    "plt.xlabel(\"log($C/C_0$)\")\n",
    "plt.ylabel(\"Temp anomaly (K)\")\n",
    "plt.show()\n",
    "\n",
    "```\n",
    "________\n",
    "````\n",
    "\n",
    "We can fit the function $y=\\hat{\\alpha} x$ to the data to estimate the value of $\\hat{\\alpha}$ in {eq}`arrhenius-2`. This is done below using the `scipy.optimize` library:\n",
    "\n",
    "\n",
    "```{code}\n",
    "# function to fit, with unknown parameters\n",
    "def func(x,a):\n",
    "  return a*x\n",
    "\n",
    "from scipy import optimize\n",
    "coeffs=optimize.curve_fit(func,x,y)[0]\n",
    "alpha_hat = coeffs[0]                    \n",
    "print(\"alpha_hat = \" , alpha_hat)\n",
    "```\n",
    "`alpha_hat =  4.3208138030469385`\n",
    "\n",
    "\n",
    "A plot of the fitted line together with the curve is shown below:\n",
    "```{code}\n",
    "plt.plot(x,y,'o')\n",
    "xx=np.array([0,max(x)])\n",
    "plt.plot(xx,alpha_hat*xx,'r')\n",
    "\n",
    "#prettify\n",
    "plt.xlabel(\"log($C/C_0$)\")\n",
    "plt.ylabel(\"Temp anomaly (K)\")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "```{figure} imgs/anomaly.png\n",
    "---\n",
    "name: arrhenius-fit\n",
    "---\n",
    "Fitting data to Arrhenius' relationship {eq}`arrhenius-2`\n",
    "```\n",
    "\n",
    "```{exercise}\n",
    "Use the calculated value of $\\hat{\\alpha}$ to produce a crude estimate of how much higher global average surface temperatures will be compared to pre-industrial levels if $\\ce{CO2}$ levels rise to twice pre-industrial levels.\n",
    "```\n",
    "\n",
    "```{toggle}\n",
    "Taking $C/C_0=2$ and $\\hat{\\alpha}=4.321$ in {eq}`arrhenius-2` gives $\\Delta T=2.99^{\\circ}C$.\n",
    "\n",
    "This result is within the [range of estimates](https://www.nature.com/articles/d41586-021-02179-1#:~:text=the%20IPCC%E2%80%99s%20best%20estimate) produced by the Intergovernmental Panel on Climate Change [IPCC].\n",
    "```\n",
    "\n",
    "## Radiation therapy\n",
    "\n",
    "Radiation therapy aims to treat cancers by exposure to radiation. The SI unit for a dose of absorbed radiation is the \"Gray\" (Gy), corresponding to the absorption of 1joule of radiation per kg of matter. Higher levels of radiation exposure result in greater clinical effect, but also increased damage to surrounding tissues.\n",
    "\n",
    "In a research paper on [Mathematical Modelling of Radiotherapy Strategies for Early Breast Cancer](https://doi.org/10.1016/j.jtbi.2005.11.015), an electron-beam driven x-ray source was used to deliver radiation to a taget site. The following experimental values were quoted in the research paper, illustrating how the amount of radiation at the site depends on the distance between the x-ray source and the target:\n",
    "\n",
    "| distance (cm) | dose (Gy) |\n",
    "| ------------- | --------- |\n",
    "| 0.1           | 15.00     |\n",
    "| 0.2           | 12.50     |\n",
    "| 0.5           | 8.75      |\n",
    "| 1.0           | 5.00      |\n",
    "| 2.7           | 1.00      |\n",
    "\n",
    "```{exercise}\n",
    "Demonstrate graphically that the (distance,dose) data approximately fits the function $y=A e^{k x}$, and find values of the constants $A,k$ that give a good fit.\n",
    "```\n",
    "\n",
    "````{toggle}\n",
    "To demonstrate that $(x,y)$ data approximately fit an exponential relationship we can show that a plot of $\\log(y)$ against $x$ follow a linear trend. This can be understood by taking the log of both sides of the exponential relationship:\n",
    "\n",
    "\\begin{align*}\n",
    "\\log(y)&=\\log(Ae^{kx})\\\\\n",
    "       &=\\log(A)+kx.\n",
    "\\end{align*}\n",
    "\n",
    "The relationship is of the form $(Y=kx+c)$, where $Y=\\log(y)$ and $c=\\log(A)$.\n",
    "\n",
    "To find the constants we could *either* :\n",
    "* fit a straight line to the $\\log(y)$ data\n",
    "* fit the exponential function to the $y$ data\n",
    "\n",
    "The two approaches are not equivalent due to the statistical way that curve fitting is done. However, they will give similar results.\n",
    "\n",
    "Here, the exponential fit has been carried out using the `scipy.optimize` library:\n",
    "\n",
    "```{code}\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x = np.array([0.1,0.2,0.5,1.0,1.3,2.0,2.7])\n",
    "y = np.array([15.00,12.50,8.75,5.00,4.00,2.00,1.00])\n",
    "\n",
    "from scipy import optimize\n",
    "\n",
    "def func(x,A,k):                          #exponential function to fit\n",
    "  return A*np.exp(k*x)\n",
    "\n",
    "coeffs=optimize.curve_fit(func,x,y)[0]    #best fit for y\n",
    "\n",
    "xx=np.linspace(0,3,100)                   #values for plot\n",
    "yy=func(xx,*coeffs)                       #apply fit to xx values\n",
    "\n",
    "fig, axs = plt.subplots(2,1)\n",
    "axs[0].semilogy(x,y,'o',xx,yy)\n",
    "axs[1].plot(x,y,'o',xx,yy)\n",
    "axs[1].set_xlabel('distance (cm)')\n",
    "axs[0].set_ylabel('log(dose)')\n",
    "axs[1].set_ylabel('dose (Gy)')\n",
    "plt.show()\n",
    "\n",
    "```\n",
    "\n",
    "```{image} imgs/smexamples_1_0.png\n",
    ":alt: fitted data\n",
    ":width: 80%\n",
    ":align: center\n",
    "```\n",
    "\n",
    "For comparison the results of the linear fit approach are shown below. Only the curve fitting part of the code needs to be replaced with\n",
    "\n",
    "```{code}\n",
    "\n",
    "def func(x,k,c):                               #linear function to fit\n",
    "  return k*x+c\n",
    "\n",
    "coeffs=optimize.curve_fit(func,x,np.log(y))[0] #best fit for log(y)\n",
    "\n",
    "xx=np.linspace(0,3,100)                        #values for plot\n",
    "yy=np.exp(func(xx,*coeffs))                    #apply fit to xx values\n",
    "\n",
    "```\n",
    "\n",
    "```{image} imgs/smexamples_1_01.png\n",
    ":alt: fitted data\n",
    ":width: 80%\n",
    ":align: center\n",
    "```\n",
    "\n",
    "The `polyfit` function from the `numpy` library can also be used to fit a straight line. However, this function can only be used to fit polynomials and is therefore less powerful than `scipy.optimize`. Its use is exemplified below:\n",
    "\n",
    "```{code}\n",
    "c = np.polyfit(x,np.log(y),1) #fit a degree 1 polynomial\n",
    "yy=np.exp(c[1]+c[0]*xx)       #convert log(y) --> y\n",
    "```\n",
    "\n",
    "________\n",
    "````\n",
    "\n",
    "A dose of radiation is often delivered in smaller amounts called [fractions](https://radiopaedia.org/articles/fractionation-radiation-therapy). This can allow healthy cells to repair sub-lethal damage to their DNA between fractions. A treatment plan may be developed that depends on the type of cancer and proximity to organs.\n",
    "\n",
    "The clinical effect of treatment can be modelled by the following \"Linear-Quadratic\" (LQ) relationship\n",
    "\n",
    "\\begin{equation}\n",
    "E = n(\\alpha d +\\beta d^2) = \\alpha D\\left(1+\\frac{d}{\\alpha/\\beta}\\right),\n",
    "\\end{equation}\n",
    "\n",
    "where $D$ is the total dose, $d$ is the dose per fraction, $n$ is the number of fractions. The first term represents lethal damage due to single-hit double strand chromsome breaks, and the second term represents lethal damage due to a combination of two sub-lethal single strand chromasome breaks. The coeffcicients $\\alpha$, $\\beta$ depend on the [tumour site and histology](https://ro-journal.biomedcentral.com/articles/10.1186/s13014-018-1040-z). Notice that if the same dose $D$ is delivered in a larger number of fractions (thereby reducing $d$) the clinical effect $E$ is reduced, with the amount of sparing depending on the $\\alpha/\\beta$ ratio.\n",
    "\n",
    "By assuming that lethal damage is Poisson distributed with rate constant $E$, we obtain that the probability of cell survival is given by\n",
    "\n",
    "```{math}\n",
    ":label: survivalp\n",
    "e^{-E}=e^{-n(\\alpha d +\\beta d^2)} = e^{-\\alpha D\\left(1+\\frac{d}{\\alpha/\\beta}\\right)}.\n",
    "```\n",
    "\n",
    "Clinical data on radiotherapy often refers to one of two quantities related to the clinical effect, which are EQD2 and BED. These quantifications are used to compare a given treatment plan to either the equivalent dose required in 2Gy fractions (EQD2) or the effective hypothetical dose if the treatment was delivered over an infinite number of \"zero fractions\" (BED).\n",
    "\n",
    "For EQD2 we may write\n",
    "\n",
    "\\begin{equation}\n",
    "E = \\alpha D\\left(1+\\frac{d}{\\alpha/\\beta}\\right) =  \\alpha \\text{EQD2}\\left(1+\\frac{2}{\\alpha/\\beta}\\right) \\quad \\Rightarrow \\quad \\text{EQD2}=D\\left(\\frac{d+\\frac{\\alpha}{\\beta}}{2+\\frac{\\alpha}{\\beta}}\\right).\n",
    "\\end{equation}\n",
    "\n",
    "For BED we may write\n",
    "\n",
    "```{math}\n",
    ":label: bed-defn\n",
    "E = \\alpha D\\left(1+\\frac{d}{\\alpha/\\beta}\\right) =  \\alpha \\text{BED}\\left(1+\\frac{0}{\\alpha/\\beta}\\right) \\quad \\Rightarrow \\quad \\text{BED}=D\\left(1+\\frac{d}{\\alpha/\\beta}\\right).\n",
    "```\n",
    "\n",
    "These two quantities have sometimes been [confused](https://www.sciencedirect.com/science/article/pii/S0360301610006334?via%3Dihub) in published research papers, which could have serious prescription consequences.\n",
    "\n",
    "\n",
    "\n",
    "```{admonition} Read more\n",
    ":class: readmore\n",
    "\n",
    "If you want to read more about this model, see (for example)\n",
    "* [Radiation Biology (textbook) chapter 5](https://www.degruyter.com/document/doi/10.1515/9783110442069-005/html?lang=en)\n",
    "* [Physics in Medicine & Biology topical review](https://iopscience.iop.org/article/10.1088/1361-6560/aaf26a/pdf)\n",
    "\n",
    "```\n",
    "\n",
    "```{exercise}\n",
    "The following experimental parameter values were quoted in the research paper on Mathematical Modelling of Radiotherapy Strategies for Early Breast Cancer:\n",
    "\n",
    "$\\begin{alignat*}{5}\n",
    "&\\bullet\\ \\text{Tumour: }\\quad &&\\alpha=0.30,\\quad   &&\\alpha/\\beta=10\\\\\n",
    "&\\bullet\\ \\text{Tissue: }      &&\\alpha=0.15,        &&\\alpha/\\beta=3\n",
    "&\\end{alignat*}$\n",
    "\n",
    "Use these values to estimate the BED {eq}`bed-defn` and survival probabilities {eq}`survivalp` for a single dose of radiation at each of the following doses (Gray):\n",
    "\n",
    "\\begin{align*}\n",
    "D=(15.00,12.50,8.75,5.00,4.00,2.00,1.00)\n",
    "\\end{align*}\n",
    "\n",
    "Your calculated values should approximately match those given in Table 1 of the [research paper](https://doi.org/10.1016/j.jtbi.2005.11.015).\n",
    "\n",
    "If you wish, you can also calculate $S^*_{tissue}$ according to equation (2b) in the paper, and therefore reproduce Figure 4 from the paper.\n",
    "\n",
    "```\n",
    "\n",
    "````{toggle}\n",
    "We can apply the given formulae as follows:\n",
    "\n",
    "```{code}\n",
    "import numpy as np\n",
    "\n",
    "dvals = np.array([15.00,12.50,8.75,5.00,4.00,2.00,1.00])\n",
    "\n",
    "# definitions\n",
    "def radioth(d,a,b):\n",
    "  BED=d*(1+d/(a/b)); S=np.exp(-a*BED);\n",
    "  return [BED,S]\n",
    "\n",
    "a1=0.30; b1=a1/10;              #tumour\n",
    "[BEDtum,Stum]=radioth(dvals,a1,b1)\n",
    "\n",
    "a2=0.15; b2=a2/3;               #tissue\n",
    "[BEDtis,Stis]=radioth(dvals,a2,b2)\n",
    "\n",
    "```\n",
    "You can then use `print` to display the results.\n",
    "\n",
    "The following code can be used to calculate the adjusted probabilities. The [`zip` function](https://www.w3schools.com/python/ref_func_zip.asp) is used here to apply the `adjst` function to the pairs of values defined by the arrays `dvals` and `Stis`\n",
    "\n",
    "```{code}\n",
    "# adjust S for tissue repair\n",
    "def adjst(d,S):\n",
    "  if d<5:\n",
    "    S=S+0.98*(d<5)*(1-S)\n",
    "  return S\n",
    "\n",
    "Ssta=[adjst(d,S) for (d,S) in zip(dvals,Stis)]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "x = np.array([0.1,0.2,0.5,1.0,1.3,2.0,2.7])\n",
    "\n",
    "plt.semilogy(x,Stum,label='tumour cells')\n",
    "plt.semilogy(x,Ssta,'--',label='tissue cells')\n",
    "plt.xlabel('distance (cm)')\n",
    "plt.ylabel('survival probability')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "```{image} imgs/smexamples_1_02.png\n",
    ":alt: reproduction-image\n",
    ":width: 80%\n",
    ":align: center\n",
    "```\n",
    "\n",
    "Here are the results:\n",
    "\n",
    "| Dose_ | BED_a | S_tumour | BED_b | S_tissue | S*tissue |\n",
    "|------ | ----- | -------- | ----- | -------- | -------- |\n",
    "| 15.00 | 37.50 | 1.30e-05 | 90.00 | 1.37e-06 | 1.37e-06 |\n",
    "| 12.50 | 28.12 | 2.17e-04 | 64.58 | 6.21e-05 | 6.21e-05 |\n",
    "|  8.75 | 16.41 | 7.29e-03 | 34.27 | 5.85e-03 | 5.85e-03 |\n",
    "|  5.00 |  7.50 | 1.05e-01 | 13.33 | 1.35e-01 | 1.35e-01 |\n",
    "|  4.00 |  5.60 | 1.86e-01 |  9.33 | 2.47e-01 | 9.85e-01 |\n",
    "|  2.00 |  2.40 | 4.87e-01 |  3.33 | 6.07e-01 | 9.92e-01 |\n",
    "|  1.00 |  1.10 | 7.19e-01 |  1.33 | 8.19e-01 | 9.96e-01 |\n",
    "\n",
    "````\n",
    "\n",
    "## Earthquakes\n",
    "\n",
    "The [`calmag.txt` dataset](https://liveuclac-my.sharepoint.com/:t:/r/personal/ucqssjm_ucl_ac_uk/Documents/Shared%20with%20Everyone/nsci0006_data/calmag.txt?csf=1&web=1&e=qfu9QE) contains 18,402 Richter scale measurements for magnitude 3+ earthquakes that were recorded in California from 1960 to 2014. The smallest and largest recorded values were 3.0 and 7.3 respectively. These data were downloaded from the U.S Geological Survey [www.usgs.gov](www.usgs.gov).\n",
    "\n",
    "We can produce a histogram of this data as shown below. The `hist` function produces a histogram, and also outputs the frequencies `n` and edge values `bin`.\n",
    "\n",
    "```{code}\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "calmag = np.loadtxt(\"data/calmag.txt\")\n",
    "n, bin, _ = plt.hist(calmag, bins=40)  \n",
    "\n",
    "plt.xlabel('Magnitude M / Richter')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "```{figure} imgs/smexamples_1_03.png\n",
    "---\n",
    "name: earthquakes-california\n",
    "---\n",
    "Frequency of Richter magnitude earthquakes in California, 1960-2014\n",
    "```\n",
    "\n",
    "The Gutenberg-Richter (GR) law predicts that in any given region and time period, the number of earthquakes that are at _least_ Richter magnitude $x$ is given by the following relationship, where $\\alpha,\\beta$ are constants:\n",
    "\n",
    "```{math}\n",
    "N_x=\\alpha e^{-\\beta x}\n",
    "````\n",
    "\n",
    "Therefore a plot of $\\ln(N_x)$ against $x$ is expected to follow a decreasing linear trend.\n",
    "\n",
    "```{exercise}\n",
    "Use the `n`, `bin` values calculated above to produce a plot of $\\ln(N_x)$ against $x$ and fit a trendline to the data. Do the data support the GR law?\n",
    "\n",
    "Hint: what result is given by `np.cumsum(n[::-1])[::-1]` ?\n",
    "```\n",
    "\n",
    "````{toggle}\n",
    "Taking the natural logarithm of the proposed relationship gives\n",
    "```{math}\n",
    "\\ln(N_x)=\\ln(\\alpha)-\\beta x\n",
    "```\n",
    "\n",
    "In the below code I used `polyfit` to obtain the trendline, but you could also use `scipy.optimize`. The data appear to fit the GR law very well!\n",
    "\n",
    "```{code}\n",
    "x=bin[0:-1]                        #ignore rightmost edge\n",
    "Nx = np.cumsum(n[::-1])[::-1]      #reverse cumsum\n",
    "plt.semilogy(x,Nx,'x')             #plot the data\n",
    "\n",
    "#fit and plot the trendline\n",
    "coeffs=np.polyfit(x,np.log(Nx),1)\n",
    "xx=np.array([0,9])\n",
    "yy=np.exp(coeffs[0]*xx+coeffs[1])\n",
    "plt.semilogy(xx,yy)\n",
    "\n",
    "plt.xlim([0,9])\n",
    "plt.xlabel('Magnitude M / Richter')\n",
    "plt.ylabel('# occurrences $\\geq M$')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "```{image} imgs/gr-law.png\n",
    ":alt: gr-fitted-data\n",
    ":width: 80%\n",
    ":align: center\n",
    "```\n",
    "________\n",
    "\n",
    "````\n",
    "\n",
    "```{exercise}\n",
    "According to the GR law with the parameters we calculated, how many magnitude 8+ earthquakes can be expected in a 30 year period?<br>\n",
    "*Hint: The expected number of earthquakes is a value less than one.*\n",
    "\n",
    "By assuming that magnitude 8+ earthquakes are Poisson-distributed, estimate the probability of a magnitude 8+ earthquake occurring in the next 30 years in California.\n",
    "\n",
    "*Hint: Taking $X\\sim\\text{Po}(\\lambda)$ where the expected number of events is $\\lambda$, the probability of no events is given by*\n",
    "\\begin{equation*}\\text{Pr}(X\\neq 0)=1-e^{-\\lambda}\\end{equation*}\n",
    "```\n",
    "\n",
    "````{toggle}\n",
    "```{code}\n",
    "\n",
    "beta = -coeffs[0]\n",
    "alpha = np.exp(coeffs[1])\n",
    "\n",
    "# Expected number of earthquakes in data time period\n",
    "N8=alpha*np.exp(-beta*8)\n",
    "\n",
    "# The dataset covers a 54 year period, so in 30 years:\n",
    "L=N8*30/54\n",
    "print(\"Expectation of 8+ earthquakes in 30 years\",L)\n",
    "\n",
    "# Pr(x>0) = 1-Pr(x=0)\n",
    "p=1-np.exp(-L)\n",
    "print(\"Estimated probabilty : {0:.1%}\".format(p))\n",
    "\n",
    "```\n",
    "\n",
    "`Expectation of 8+ earthquakes in 30 years 0.39837`<br>\n",
    "`Estimated probabilty : 32.9%`\n",
    "\n",
    "________\n",
    "\n",
    "````\n",
    "\n",
    "```{warning}\n",
    "We should be extremely careful when making estimates based on extrapolation beyond the domain of the available data. A comic illustration of this warning can be found at\n",
    "[https://xkcd.com/1007/](https://xkcd.com/1007/)\n",
    "```\n",
    "\n",
    "## Heart rate monitoring\n",
    "\n",
    "Many wearable devices allow heart rate and activity data to be tracked and downloaded as txt or csv files. It may be possible to estimate [circadian rhythms](https://nigms.nih.gov/education/fact-sheets/Pages/circadian-rhythms.aspx) from this data.\n",
    "\n",
    "The [hrdata2.csv](https://liveuclac-my.sharepoint.com/:x:/r/personal/ucqssjm_ucl_ac_uk/Documents/Shared%20with%20Everyone/nsci0006_data/hrdata2.csv?d=w30f852f1fa3e471a92661dfb7dd70ba2&csf=1&web=1&e=ew8gGA) dataset contains \"fitbit\" measurements of activity and heart rate (HR) for a single individual, obtained from a [recent research paper](https://doi.org/10.1016/j.crmeth.2021.100058). The data are for a period of 96 hours, averaged every five minutes. The HR is measured in beats per minute (bpm), and the activity level is measured in steps per minute.\n",
    "\n",
    "The heart rate can be modelled by the equation\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{HR} = \\mu + A\\sin\\left(\\frac{\\pi}{12}t\\right)+E(a)+\\epsilon\n",
    "\\end{equation}\n",
    "\n",
    "where $\\mu$ is the average background HR, $A$ is the amplitude of the 24hr circadian cycle, and $\\epsilon$ is statistical error (e.g. due to measurement inaccuracies).\n",
    "\n",
    "The activity effect $E(a)$ is the increase in HR due to activity $a$. To estimate the background circadian rhythm, we will attempt to remove the activity effect from the data.\n",
    "\n",
    "We begin by selecting the data for waking periods only. Plotting the activity $a$ against $(\\text{HR}-\\mu)$ shows the effect of the activity.\n",
    "\n",
    "Due to background noise and circadian variation there is a wide band of HR measurements, which need to be statistically averaged. Doing this calculation is beyond the scope of the course, so the activity effect has been estimated for you. The `Activity_effect` column in the dataset gives the estimated effect size $E(a)$. The predicted relationship is plotted below in red, with the measured data shown in blue.\n",
    "\n",
    "```{code}\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#import the data\n",
    "df = pd.read_csv('hrdata2.csv')\n",
    "\n",
    "# get waking data\n",
    "df=df.loc[df['Sleep'] == False]\n",
    "df=df.sort_values(by='Activity')\n",
    "\n",
    "#average resting waking heart rate\n",
    "mu=np.mean(df.loc[df['Activity']==0,'HR'])\n",
    "print(\"Resting HR (awake) : \",mu)\n",
    "\n",
    "x=df['Activity']           #activity\n",
    "y=df['HR']-mu              #adjusted HR\n",
    "z=df['Activity_effect']    #activity effect\n",
    "\n",
    "plt.plot(x,y,'o')          #(activity,HR data)\n",
    "plt.plot(x,z,'r')          #(activity,effect) estimates\n",
    "\n",
    "#prettify\n",
    "plt.xlabel('Activity, a')\n",
    "plt.ylabel('HR effect, E(a)')\n",
    "plt.show()\n",
    "\n",
    "```\n",
    "`Resting HR (awake) :  62.71232876712329`\n",
    "\n",
    "```{figure} imgs/heart-activity.png\n",
    "---\n",
    "name: hr-activity\n",
    "---\n",
    "Heart rate increase due to activity (bpm)\n",
    "```\n",
    "\n",
    "The plot suggests that the effect of additional activity on HR is not linear. The good news is that light activity such as a gentle walk results in an appreciable heart rate effect. At a level of just 20 steps per minute this person's HR increased by around 20bpm. However, further increases in activity level resulted in a smaller HR effect until around 100 steps per minute (a moderate walk). At more vigorous levels of activity corresponding to a vigorous walk or light jog we again start to see greater effect of additional activity. Can you use your knowledge of the cardiovascular system to suggest why this might be?\n",
    "\n",
    "\n",
    "```{exercise}\n",
    "Using the given dataset, plot the adjusted HR against time.\n",
    "\n",
    "On the same axes, plot the curve\n",
    "\\begin{equation*}\n",
    "y=\\mu+A\\sin\\left(\\frac{\\pi}{12} t\\right),\n",
    "\\end{equation*}\n",
    "\n",
    "where $A,\\mu$ are \"best fit\" estimates for the data.\n",
    "```\n",
    "\n",
    "````{toggle}\n",
    "```{code}\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#import the data\n",
    "df = pd.read_csv('hrdata2.csv')\n",
    "t=df['Sec']/60          #time\n",
    "y=df['HR_adjusted']     #adjusted heart rate\n",
    "\n",
    "\n",
    "#plot the data\n",
    "plt.plot(t,y,'k',label='data')\n",
    "\n",
    "# Fitted curve\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def func(t, mu, A):\n",
    "    return mu + A*np.sin(np.pi*t/12.0)\n",
    "\n",
    "coeffs = curve_fit(func, t, y)[0]\n",
    "print(coeffs)\n",
    "\n",
    "tfit = np.linspace(0,96,100)\n",
    "yfit = func(tfit,*coeffs)\n",
    "plt.plot(tfit,yfit,'r',label='fit')\n",
    "\n",
    "#prettify\n",
    "plt.xlabel('time (hrs)')\n",
    "plt.ylabel('Heart rate (bpm)')\n",
    "plt.xlim([0,96])\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "```\n",
    "`[61.56597222,  4.04033287]`\n",
    "\n",
    "```{image} imgs/hr-circadian.png\n",
    ":alt: Estimating the circadian heart rate cycle\n",
    ":align: center\n",
    "```\n",
    "\n",
    "Although the plotted data still contains a large amount of variation/noise, we appear to have done a reasonable job of identifying a circadian rhythm, with the basal heart rate for this person being around 61-62bpm with a daily (resting) variation of $\\pm$4bpm.\n",
    "\n",
    "In their research paper, the authors found that the circadian rhythms for some of their volunteers did not align with the sleep-wake cycle. For instance, one of their participants was undertaking shift work, but their daily heart-rate cycle remained aligned to a standard day/night pattern.\n",
    "\n",
    "_________\n",
    "````"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.10.3"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "source_map": [
   13
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}