{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3060399",
   "metadata": {},
   "source": [
    "# Viral trends solutions\n",
    "\n",
    "## {numref}`ex-vt1`\n",
    "\n",
    "Use the code given in the homework sheet to import the data :\n",
    "\n",
    "````{toggle}\n",
    "```{code}\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('data_2022-Aug-17.csv')\n",
    "df=df.iloc[::-1] #data in reverse order\n",
    "\n",
    "x=np.array(df['date'])\n",
    "y=np.array(df['newCasesBySpecimenDate'])\n",
    "\n",
    "from datetime import date as dt\n",
    "date=dt.fromisoformat\n",
    "dt0 = date(x[0])\n",
    "x=[abs(date(x[i])-dt0).days for i in range(len(x))]\n",
    "```\n",
    "````\n",
    "\n",
    "Isolate a wave \"by eye\" and find the running total number of cases\n",
    "\n",
    "```{code}\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x=np.array(x[750:850])\n",
    "y=np.array(y[750:850])\n",
    "\n",
    "fig, ax = plt.subplots(1, 2,figsize=(8,2))\n",
    "ax[0].plot(x,y,'o')\n",
    "\n",
    "#subtracting baseline number of cases\n",
    "Y = np.cumsum(y-min(y))\n",
    "ax[1].plot(x,Y,'o')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "```{image} imgs/viral000.png\n",
    ":alt: baseline-data\n",
    ":width: 90%\n",
    ":align: center\n",
    "```\n",
    "\n",
    "Define the logistic function\n",
    "\n",
    "```{code}\n",
    "def logistic_fun(x,K,x0,s):\n",
    "  return K/(1+np.exp(-(x-x0)/s))\n",
    "```\n",
    "\n",
    "`````{note}\n",
    "It is possible to fit the function without normalising, but to do this we have to help the optimizer locate the parameter values by providing bounds.\n",
    "\n",
    "````{toggle}\n",
    "We can identify suitable parameter bounds by trying out some coefficient values in the logistic function until we get some that look roughly correct:\n",
    "\n",
    "```{code}\n",
    "xtest = np.linspace(750,850)\n",
    "ytest = logistic_fun(xtest,2.5e6,780,10)\n",
    "plt.plot(xtest,ytest)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "```{image} imgs/viral001.png\n",
    ":alt: params-est\n",
    ":width: 80%\n",
    ":align: center\n",
    "```\n",
    "\n",
    "Provide coefficient bounds that span the indicated values:\n",
    "\n",
    "```{code}\n",
    "from scipy.optimize import curve_fit\n",
    "bds=((1e6,760,1),(5e6,840,100))\n",
    "params=curve_fit(logistic_fun,x,Y,bounds=bds)[0]\n",
    "print(params) # these are the values we found\n",
    "\n",
    "# plot the result :\n",
    "plt.plot(x,Y,'o')\n",
    "Y_fit=logistic_fun(x,*params)\n",
    "plt.plot(x,Y_fit)\n",
    "plt.show()\n",
    "\n",
    "```\n",
    "\n",
    "```{image} imgs/viral002.png\n",
    ":alt: viral-fit1\n",
    ":width: 80%\n",
    ":align: center\n",
    "```\n",
    "````\n",
    "`````\n",
    "\n",
    "The homework suggested to normalize the data. You could plot the result after the following step, to check correctness:\n",
    "\n",
    "```{code}\n",
    "def my_normalize(v):\n",
    "  a=min(v); b=max(v)\n",
    "  vhat=(v-a)/(b-a)\n",
    "  return vhat,a,b\n",
    "\n",
    "xhat,L,R = my_normalize(x)\n",
    "Yhat,D,U = my_normalize(Y)\n",
    "```\n",
    "\n",
    "Now fit the logistic function. You could plot the result after the following step, to check correctness:\n",
    "\n",
    "```{code}\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "params=curve_fit(logistic_fun,xhat,Yhat)[0]\n",
    "Yhat_fit=logistic_fun(xhat,*params)\n",
    "```\n",
    "\n",
    "\n",
    "To  \"un-normalise\" we perform the reverse of the normalization steps:\n",
    "\n",
    "```{code}\n",
    "def un_normalize(vhat,a,b):\n",
    "  return vhat*(b-a)+a\n",
    "\n",
    "Yfit = un_normalize(Yhat_fit,D,U)\n",
    "plt.plot(x,Y,'o')\n",
    "plt.plot(x,Yfit)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "```{image} imgs/viral003.png\n",
    ":alt: viral-fit2\n",
    ":width: 70%\n",
    ":align: center\n",
    "```\n",
    "\n",
    "Finally, to plot the daily cases we reverse the accumulation step\n",
    "\n",
    "```{code}\n",
    "yfit = np.diff(Yfit)+min(y)\n",
    "plt.plot(x,y,'o')\n",
    "plt.plot(x[0:-1],yfit)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "```{image} imgs/viral004.png\n",
    ":alt: viral-final\n",
    ":width: 70%\n",
    ":align: center\n",
    "```\n",
    "\n",
    "## {numref}`ex-vt2`\n",
    "\n",
    "Import the call me maybe data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aeb968d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('call-me-maybe.csv')\n",
    "x=np.array(df['week'])\n",
    "h=np.array(df['hits'])\n",
    "y=np.cumsum(h)           #accumulate  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a935290",
   "metadata": {},
   "source": [
    "`````{note}\n",
    "Again, we can do the fit without normalising if we tinker with the parameters to establish suitable bounds:\n",
    "\n",
    "````{toggle}\n",
    "\n",
    "```{code}\n",
    "def frechet(x,A,k,s):\n",
    "  y=A*np.exp(-(x/k)**(-s))\n",
    "  return y\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "bds=((1e3,50,2),(1e4,500,10))\n",
    "params=curve_fit(frechet,x,y,bounds=bds)[0]\n",
    "print(params)\n",
    "\n",
    "Yfit = frechet(x,*params)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(x,y,'b.')\n",
    "plt.plot(x,Yfit)\n",
    "plt.show()\n",
    "\n",
    "```\n",
    "\n",
    "```{image} imgs/maybe01.png\n",
    ":alt: cmm1\n",
    ":width: 80%\n",
    ":align: center\n",
    "```\n",
    "````\n",
    "`````\n",
    "\n",
    "With normalisation:\n",
    "\n",
    "```{code}\n",
    "# normalise\n",
    "xhat=x/len(x)\n",
    "yhat=y/max(y)\n",
    "\n",
    "# curve fit\n",
    "from scipy.optimize import curve_fit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def frechet(x,k,s):\n",
    "  return np.exp(-(x/k)**(-s))\n",
    "\n",
    "bds=((0.01,0.01),(1,100))\n",
    "params=curve_fit(frechet,xhat,yhat,bounds=bds)[0]\n",
    "print(params)\n",
    "\n",
    "Yfit = frechet(xhat,*params)\n",
    "\n",
    "plt.plot(xhat,yhat,'b.')\n",
    "plt.plot(xhat,Yfit)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "```{image} imgs/maybe02.png\n",
    ":alt: cmm2\n",
    ":width: 70%\n",
    ":align: center\n",
    "```\n",
    "\n",
    "Showing the weekly hits :\n",
    "```{code}\n",
    "yfit = np.diff(max(y)*Yfit)\n",
    "plt.plot(x,h,'b.')\n",
    "plt.plot(x[0:-1],yfit)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "```{image} imgs/maybe03.png\n",
    ":alt: cmm-final\n",
    ":width: 70%\n",
    ":align: center\n",
    "```\n",
    "\n",
    "The distribution pdf has a similar shape to the data (variance, skeweness) but a lower peak (kurtosis)."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.10.3"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "source_map": [
   13,
   171,
   179
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}